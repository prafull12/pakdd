% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage[options ]{algorithm2e}
\usepackage{algorithm}% http://ctan.org/pkg/algorithm
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{mathpazo} % Use the Palatino font by default
\usepackage{array}% http://ctan.org/pkg/array
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Impact of outliers and loss functions on XGBoost}

%Contribution Title\thanks{Supported by organization x.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Rao Kotagiri\inst{1}\orcidID{a} \and
Ziren\inst{1}\orcidID{b} \and
Prafull\inst{1}\orcidID{c}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{The University of Melbourne}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
\paragraph{} The quantity of data we generate each day keeps on increasing. Today we are producing Exabytes of data per day, which is equal to the total data we had on earth in the year 2000. Various techniques are being used to utilize the data and gain knowledge from it. One such method is prediction modelling in machine learning. The accuracy of these models depends on multiple factors, of which one of the critical aspects is the presence of outliers. Outliers can induce additional loss, thus reducing the accuracy of prediction, and a small variation can sometimes lead to disastrous results. The two approaches in the proposal are based on outlier detection and outlier handling techniques. The first approach utilizes traditional outlier detection concepts like distance or similarity measure, cluster and spatial techniques for detecting and removing these outliers and thus making the predictions more accurate for machine learning algorithm called XGBoost. The second approach is based on the addition of user-defined loss functions, which are capable of making XGBoost model tolerable to outliers, thus lifting the requirement of removing the outliers. \\
\\


\keywords{Outlier Detection  \and Removal \and  Loss Function \and XGBoost.}
\end{abstract}
%
%
%
\section{Introduction}
\paragraph{} In the majority of prediction problems, we examine a vast quantity of features. To obtain quality predictions, one of the first steps requires us to alleviate the impact of outliers on the learner. The learner can be made more efficient in two different ways. The first approach utilizes traditional outlier detection concepts like distance, similarity, cluster and spatial techniques for detecting and removing outliers, thus making the predictions more accurate for XGBoost. In case the outliers are not errors, outlier detection in the first approach can lead us to the process which generated the outliers. Such outliers can help us locate a malicious node in a network or a fraud transaction for a user. 

\paragraph{}The second approach is based on the addition of user-defined loss functions, which are capable of making XGBoost model tolerable to outliers, thus lifting the requirement of removing the outliers. In this approach, we penalize the outliers based on the domain requirement. For example, we want to make predictions for the right time to reach the airport to board a flight. What if we reach 45 minutes before or 5 minutes after the plane takes off? In both cases, there is a loss of time, but the magnitude of time alone does not justify the intensity of loss. Similarly, outliers can result in various types of loss, which can be tackled by using different user-defined loss functions.
\
\paragraph{} Although we have theoretical definitions for outliers, an accurate description of an outlier is based on the premises formed on data and the method adopted to deal with outliers. A generic version of the definition by Professor Hawkins is as follows. \textit{An outlier is an observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism.
} The applications of outlier detection are not limited to improving the model performance for a learner. 

\subsection{Application}
Information about outlier can be extended in fields like finance, medical, etc. Some domain-specific implementation of outlier detection is as follows.

\paragraph{Intrusion Detection System: }There are applications which maintain data regarding a system call to the operating system, network logs, etc. Any abnormal data can lead us to a malicious event.
\paragraph{Credit-card fraud:} Credit card information like its number and security code at times is compromised. A particular credit card stores the patterns of shopping for a user, in case a user makes an unlikely purchase, the information can be treated and dealt as an outlier.
\paragraph{Environmental Sensors:} Devices are installed at strategic locations to monitor ecological behaviour. Any variation in the behaviour based on data points can be a possible event of interest.
\paragraph{Medical Diagnosis:} In medical, the data comes in many forms like images from MRI scans etc. An abnormal pattern in the image can be a disease.

\subsection{Problem Statement}
\paragraph{}How can we increase the accuracy of prediction for XGBoost? Alternatively, we can say that we are interested in finding reasons that induces inefficient behaviour in the machine learning algorithm and how can we tackle these problems. The question arises because we intend to gain knowledge from abundant data and make predictions. The predictions on real time event are quantified using loss functions. They map the event to a number which signifies the cost linked with that event. Our intention here is to investigate the performance of XGBoost model, for different user defined loss functions.

\paragraph{} A useful outlier might lead us to a cure for disease or detection of fraud in the transaction, whereas most of the outliers are just useless data, generated by an erroneous process or wrong calculation. There are several ways of detecting outliers, some based on existing statistical methods like extreme value analysis, others explicitly designed for outlier detection like the isolation forest. In this paper, we propose an outlier detection framework that improves the accuracy of prediction for XGBoost by detecting and removing outliers. The outlier detection framework also intends to identify a threshold region as a percentage of data instance that can help us understand a trend with outlier detection.

\section{Related Work}

% outlier detection methods

\paragraph{} A basic analogy of understanding outliers is in terms of local and global outliers. A global outlier is identified using a binary value of 0 and 1 whereas a local outlier is assigned a score based on the extent to which a point is an outlier. Usually, there is less prior known outliers. As a result, supervised learning methods are less effective in detection. Unsupervised learning methods, on the other hand, works well, as the methods are meant to deal with tasks with less prior information.

\paragraph{} The distribution of data can provide informative parameters,  which can be used for outlier detection. Such techniques are implemented on univariate datasets and are less effective., as the distribution parameters like mean, standard deviation are sensitive to outliers. 
Next in line is a metric based on depth, which stacks data point into arch layers. The point on the outer layer has a higher tendency to be an outlier. Less efficient for high dimensional data.

\paragraph{} The distance-based metric is also used to locate outliers. The technique utilizes the concepts of k nearest neighbours, where data points are ranked based on the distance with their neighbour. We then determine outliers by partitioning the data.  Finally, we also have K Nearest Neighbour and Local outlier factor-based techniques. Both the technoques utilizes concepts similar to density based approach.

% previous works on loss functions

% basic concept of XGBoost



% what is new loss function actually doing? reasons?

% consider mathematical expression in this section?

\section{Background}

\subsection{Summary}
\subsection{XGBoost}
\subsection{Data Types}
\subsection{Loss Functions}
\subsection{Tree Model Vs Other Models}
\subsection{Outlier Detection Techniques}

\section{Experimental Setup}
\subsection{Summary}
\subsection{Datasets and Source}
\subsection{Architecture}
\subsection{Experiment Design}

\section{Methodology + Implementation}

\section{Outcomes}

\subsection{Comparison}

\section{Discussion}

\section{Conclusion}




%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%

\end{document}
